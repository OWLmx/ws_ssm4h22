[stance1:inference] Activating env....
Activating env [py38ptpl]
guild_version:             0.8.0
guild_install_location:    /home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/guild
guild_home:                /home/serrano/projects/SMM4H22/tracking/.guild
guild_resource_cache:      /home/serrano/projects/SMM4H22/tracking/.guild/cache/resources
installed_plugins:         config_flags, cpu, dask, disk, dvc, exec_script, gpu, ipynb, keras, memory, perf, python_script, queue, skopt
python_version:            3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
python_exe:                /home/serrano/miniconda3/envs/py38ptpl/bin/python
platform:                  Linux 4.18.0-193.el8.x86_64 x86_64
psutil_version:            5.8.0
tensorboard_version:       2.6.0
cuda_version:              11.4
nvidia_smi_version:        470.82.01
latest_guild_version:      0.8.1
A newer version of Guild AI is available. Run 'pip install guildai --upgrade' to install it.
*** Check tha [guild_home] is correctly set ***
===============================================
*** Available operations (execute _guild help_ for more info) ***
Refreshing flags...
WARNING: cannot import flags from src/stance_preprocess.py: ModuleNotFoundError: No module named 'fasttext' (run with guild --debug for details)
WARNING: cannot import flags from src/prepare_txts.py: ModuleNotFoundError: No module named 'negspacy' (run with guild --debug for details)
prepare_data                      Generate Dataframes with hydrated examples from previously processed splits, texts, annotations
prepare_splits                    Create a summary table with reference to all files and assign a split to each entry
prepare_submission                from predictions in DF (subtask 2 & 3 ) generate ann files for submission
prepare_task2_stance              Prepare official training data for stance Task2
prepare_texts                     Preprocess txt files (clean, segment, etc.)
base-model:evaluate               Run official evalation script
stance1:inference                 apply transforemr
stance1:inference-sentiment       apply transforemr
stance1:pipeline_inference_event  
stance1:train                     Train model Transformer based classifier
Running script ....
New Run
Refreshing flags...
WARNING: cannot import flags from src/stance_preprocess.py: ModuleNotFoundError: No module named 'fasttext' (run with guild --debug for details)
WARNING: cannot import flags from src/prepare_txts.py: ModuleNotFoundError: No module named 'negspacy' (run with guild --debug for details)
Resolving train dependency
Using run e21e499257324d6381c27d5918f092fe for train resource
WARNING: nothing resolved for operation:train
Resolving prepare_task2_stance dependency
Using run 6d4c5793a53c4ff2bf830020a0248f0f for prepare_task2_stance resource
INFO: [numexpr.utils] Note: NumExpr detected 20 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
INFO: [__main__] Available GPUs: 1
INFO: [__main__] 
=========  Loading model [microsoft/deberta-large-mnli::model]  ==========
model => {'num_labels': 3}
Traceback (most recent call last):
  File "/home/serrano/projects/SMM4H22/tracking/.guild/runs/086b76071e954af2a6a625489bf5b1a6/.guild/sourcecode/src/infer-cls_with_transformer.py", line 147, in <module>
    main(**vars(args))
  File "/home/serrano/projects/SMM4H22/tracking/.guild/runs/086b76071e954af2a6a625489bf5b1a6/.guild/sourcecode/src/infer-cls_with_transformer.py", line 116, in main
    rs = predict(tgt_data, model_path, model_type, input_feats, label_mapper=label_mapper, rs_prefix=rs_prefix, output_logits=output_logits, **kwargs)
  File "/home/serrano/projects/SMM4H22/tracking/.guild/runs/086b76071e954af2a6a625489bf5b1a6/.guild/sourcecode/src/infer-cls_with_transformer.py", line 34, in predict
    predictor = estimator if estimator else TransformerClassifierInferenceWrapper(model_path, tokenizer_type=model_type, **kwargs)
  File "/home/serrano/projects/SMM4H22/tracking/.guild/runs/086b76071e954af2a6a625489bf5b1a6/.guild/sourcecode/src/plibs/utils/transformers_utils.py", line 43, in __init__
    self.model = AutoModelForSequenceClassification.from_pretrained(model_path, **kwargs)
  File "/home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 413, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 580, in from_pretrained
    config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/transformers/configuration_utils.py", line 550, in get_config_dict
    configuration_file = get_configuration_file(
  File "/home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/transformers/configuration_utils.py", line 841, in get_configuration_file
    all_files = get_list_of_files(
  File "/home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/transformers/file_utils.py", line 1952, in get_list_of_files
    return list_repo_files(path_or_repo, revision=revision, token=token)
  File "/home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/huggingface_hub/hf_api.py", line 602, in list_repo_files
    info = self.model_info(
  File "/home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/huggingface_hub/hf_api.py", line 586, in model_info
    r.raise_for_status()
  File "/home/serrano/miniconda3/envs/py38ptpl/lib/python3.8/site-packages/requests/models.py", line 960, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/model
---------- FINALIZED -------------
